{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9131d48-2f5e-464d-988d-c621b317b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a7669a-fffd-41ba-ba27-83888903f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porcine, P12AC1\n",
    "offx_path = 'training_data/porcine_P12AC1/P12AC1S1_OffX.csv'\n",
    "offy_path = 'training_data/porcine_P12AC1/P12AC1S1_OffY.csv'\n",
    "equi_path = 'training_data/porcine_P12AC1/P12AC1S1_Equibiaxial.csv'\n",
    "strx_path = 'training_data/porcine_P12AC1/P12AC1S1_StripX.csv'\n",
    "stry_path = 'training_data/porcine_P12AC1/P12AC1S1_StripY.csv'\n",
    "\n",
    "data_offx = np.genfromtxt(offx_path,delimiter=',')\n",
    "data_offx = data_offx[:-3] #Remove bad data\n",
    "data_offy = np.genfromtxt(offy_path,delimiter=',')\n",
    "data_equi = np.genfromtxt(equi_path,delimiter=',')\n",
    "data_equi = data_equi[:-20]\n",
    "data_strx = np.genfromtxt(strx_path,delimiter=',')\n",
    "data_stry = np.genfromtxt(stry_path,delimiter=',')\n",
    "data_stry = data_stry[:-29]\n",
    "n_offx = data_offx.shape[0]\n",
    "n_offy = data_offy.shape[0]\n",
    "n_equi = data_equi.shape[0]\n",
    "n_strx = data_strx.shape[0]\n",
    "n_stry = data_stry.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075ca2fa-eaa3-41da-81e6-33a524a59f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave Nothing Out\n",
    "data = np.vstack((data_offx, data_offy, data_equi, data_strx, data_stry))\n",
    "\n",
    "X = np.vstack((data[:,0], data[:,2]))\n",
    "X = np.transpose(X,[1,0])\n",
    "Y = np.vstack((data[:,1], data[:,3]))\n",
    "Y = np.transpose(Y,[1,0])\n",
    "\n",
    "#The stresses in the csv files are PK1 stress. Convert it to Cauchy stress\n",
    "F = np.zeros([X.shape[0],3,3])\n",
    "F[:,0,0] = X[:,0]\n",
    "F[:,1,1] = X[:,1]\n",
    "F[:,2,2] = 1/(X[:,0]*X[:,1])\n",
    "P = np.zeros_like(F)\n",
    "P[:,0,0] = Y[:,0]\n",
    "P[:,1,1] = Y[:,1]\n",
    "sigma = P*F #Since F_T=F\n",
    "Y = np.zeros_like(X)\n",
    "Y[:,0] = sigma[:,0,0]\n",
    "Y[:,1] = sigma[:,1,1]\n",
    "\n",
    "save_path = 'training_data/P12AC1_xybsxsy.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X,Y], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead273d-61f1-4bca-87c8-6567227cf239",
   "metadata": {},
   "source": [
    "# Leave one out\n",
    "There are 5 experimental protocols. Save 5 .npy files each of which contains the results of 4 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b650d95-2015-4115-bd6d-95661c2ddccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave Strip-y out\n",
    "mask = np.ones(data.shape[0], dtype=np.bool)\n",
    "mask[n_offx + n_offy + n_equi + n_strx:] = 0\n",
    "X2 = X[mask,:]\n",
    "Y2 = Y[mask,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_xybsx.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X2,Y2], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed5999e-4562-466e-9513-0efcf72d5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave Strip-x out\n",
    "mask = np.ones(data.shape[0], dtype=np.bool)\n",
    "mask[n_offx + n_offy + n_equi: n_offx + n_offy + n_equi + n_strx] = 0\n",
    "X3 = X[mask,:]\n",
    "Y3 = Y[mask,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_xybsy.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X3,Y3], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ff72e35-d545-4b4e-9724-35b51c6d24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave Equibiaxial out\n",
    "mask = np.ones(data.shape[0], dtype=np.bool)\n",
    "mask[n_offx + n_offy: n_offx + n_offy + n_equi] = 0\n",
    "X4 = X[mask,:]\n",
    "Y4 = Y[mask,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_xysxsy.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X4,Y4], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf7465a7-5a61-4bd9-b1a8-992576adc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave Off-y out\n",
    "mask = np.ones(data.shape[0], dtype=np.bool)\n",
    "mask[n_offx: n_offx + n_offy] = 0\n",
    "X5 = X[mask,:]\n",
    "Y5 = Y[mask,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_xbsxsy.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X5,Y5], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb265f6-f4ac-4804-90a9-17bda08d6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave Off-x out\n",
    "mask = np.ones(data.shape[0], dtype=np.bool)\n",
    "mask[: n_offx] = 0\n",
    "X6 = X[mask,:]\n",
    "Y6 = Y[mask,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_ybsxsy.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X6,Y6], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938a795-19ac-4803-bf97-1aaed1a6c1d6",
   "metadata": {},
   "source": [
    "## 80 - 20 Split of each loading protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8693bec8-89ef-4035-a3fa-db0aefe3559c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First 80% of offx\n",
    "n80 = int(np.floor(n_offx*0.8))\n",
    "X80 = X[:n80,:]\n",
    "Y80 = Y[:n80,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_x80.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X80,Y80], allow_pickle=True)\n",
    "\n",
    "#Last 20% of offx\n",
    "X20 = X[n80:n_offx]\n",
    "Y20 = Y[n80:n_offx]\n",
    "\n",
    "save_path = 'training_data/P12AC1_x20.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X20,Y20], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a01b471-b662-47ba-b944-7faf5aa33b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 80% of offy\n",
    "n80 = int(np.floor(n_offy*0.8))\n",
    "X80 = X[n_offx:n_offx + n80,:]\n",
    "Y80 = Y[n_offx:n_offx + n80,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_y80.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X80,Y80], allow_pickle=True)\n",
    "\n",
    "#Last 20% of offy\n",
    "X20 = X[n_offx + n80:n_offx + n_offy]\n",
    "Y20 = Y[n_offx + n80:n_offx + n_offy]\n",
    "\n",
    "save_path = 'training_data/P12AC1_y20.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X20,Y20], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb97329d-2698-4ef6-8927-8f468a07638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 80% of equi\n",
    "n80 = int(np.floor(n_equi*0.8))\n",
    "X80 = X[n_offx + n_offy:n_offx + n_offy + n80,:]\n",
    "Y80 = Y[n_offx + n_offy:n_offx + n_offy + n80,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_b80.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X80,Y80], allow_pickle=True)\n",
    "\n",
    "#Last 20% of equi\n",
    "X20 = X[n_offx + n_offy + n80:n_offx + n_offy + n_equi]\n",
    "Y20 = Y[n_offx + n_offy + n80:n_offx + n_offy + n_equi]\n",
    "\n",
    "save_path = 'training_data/P12AC1_b20.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X20,Y20], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f203f97-b669-4f1e-8bd3-5d3e8a6d3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 80% of strx\n",
    "n80 = int(np.floor(n_strx*0.8))\n",
    "X80 = X[n_offx + n_offy + n_equi:n_offx + n_offy + n_equi + n80,:]\n",
    "Y80 = Y[n_offx + n_offy + n_equi:n_offx + n_offy + n_equi + n80,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sx80.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X80,Y80], allow_pickle=True)\n",
    "\n",
    "#Last 20% of strx\n",
    "X20 = X[n_offx + n_offy + n_equi + n80:n_offx + n_offy + n_equi + n_strx]\n",
    "Y20 = Y[n_offx + n_offy + n_equi + n80:n_offx + n_offy + n_equi + n_strx]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sx20.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X20,Y20], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ece3274-0004-4c04-8ff2-1119c987ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 80% of stry\n",
    "n80 = int(np.floor(n_stry*0.8))\n",
    "X80 = X[n_offx + n_offy + n_equi + n_strx:n_offx + n_offy + n_equi + n_strx + n80,:]\n",
    "Y80 = Y[n_offx + n_offy + n_equi + n_strx:n_offx + n_offy + n_equi + n_strx + n80,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sy80.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X80,Y80], allow_pickle=True)\n",
    "\n",
    "#Last 20% of stry\n",
    "X20 = X[n_offx + n_offy + n_equi + n_strx + n80:]\n",
    "Y20 = Y[n_offx + n_offy + n_equi + n_strx + n80:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sy20.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X20,Y20], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e98808-2c59-450e-b355-c338f07a23ac",
   "metadata": {},
   "source": [
    "## 60 - 40 Split of each loading protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f94621-899a-4828-8256-e3e83b7d0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 60% of offx\n",
    "n60 = int(np.floor(n_offx*0.6))\n",
    "X60 = X[:n60,:]\n",
    "Y60 = Y[:n60,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_x60.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X60,Y60], allow_pickle=True)\n",
    "\n",
    "#Last 40% of offx\n",
    "X40 = X[n60:n_offx]\n",
    "Y40 = Y[n60:n_offx]\n",
    "\n",
    "save_path = 'training_data/P12AC1_x40.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X40,Y40], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b027a8-5681-40b1-ae8d-07f0ebd4800c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First 60% of offy\n",
    "n60 = int(np.floor(n_offy*0.6))\n",
    "X60 = X[n_offx:n_offx + n60,:]\n",
    "Y60 = Y[n_offx:n_offx + n60,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_y60.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X60,Y60], allow_pickle=True)\n",
    "\n",
    "#Last 40% of offy\n",
    "X40 = X[n_offx + n60:n_offx + n_offy]\n",
    "Y40 = Y[n_offx + n60:n_offx + n_offy]\n",
    "\n",
    "save_path = 'training_data/P12AC1_y40.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X40,Y40], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759a05be-2129-4a72-adc1-c4faa3ab2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 60% of equi\n",
    "n60 = int(np.floor(n_equi*0.6))\n",
    "X60 = X[n_offx + n_offy:n_offx + n_offy + n60,:]\n",
    "Y60 = Y[n_offx + n_offy:n_offx + n_offy + n60,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_b60.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X60,Y60], allow_pickle=True)\n",
    "\n",
    "#Last 40% of equi\n",
    "X40 = X[n_offx + n_offy + n60:n_offx + n_offy + n_equi]\n",
    "Y40 = Y[n_offx + n_offy + n60:n_offx + n_offy + n_equi]\n",
    "\n",
    "save_path = 'training_data/P12AC1_b40.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X40,Y40], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c70f988-9ce1-42a9-83b9-c0796fb3af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 60% of strx\n",
    "n60 = int(np.floor(n_strx*0.6))\n",
    "X60 = X[n_offx + n_offy + n_equi:n_offx + n_offy + n_equi + n60,:]\n",
    "Y60 = Y[n_offx + n_offy + n_equi:n_offx + n_offy + n_equi + n60,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sx60.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X60,Y60], allow_pickle=True)\n",
    "\n",
    "#Last 40% of strx\n",
    "X40 = X[n_offx + n_offy + n_equi + n60:n_offx + n_offy + n_equi + n_strx]\n",
    "Y40 = Y[n_offx + n_offy + n_equi + n60:n_offx + n_offy + n_equi + n_strx]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sx40.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X40,Y40], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710e2565-301b-4efe-969e-b145bdcae357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 60% of stry\n",
    "n60 = int(np.floor(n_stry*0.6))\n",
    "X60 = X[n_offx + n_offy + n_equi + n_strx:n_offx + n_offy + n_equi + n_strx + n60,:]\n",
    "Y60 = Y[n_offx + n_offy + n_equi + n_strx:n_offx + n_offy + n_equi + n_strx + n60,:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sy60.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X60,Y60], allow_pickle=True)\n",
    "\n",
    "#Last 40% of stry\n",
    "X40 = X[n_offx + n_offy + n_equi + n_strx + n60:]\n",
    "Y40 = Y[n_offx + n_offy + n_equi + n_strx + n60:]\n",
    "\n",
    "save_path = 'training_data/P12AC1_sy40.npy'\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f,[X40,Y40], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d21e8-7b6f-47a2-9c9e-852303434485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
